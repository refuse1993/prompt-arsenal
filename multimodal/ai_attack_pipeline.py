"""
AI Attack Pipeline Manager
API í”„ë¡œí•„ì„ í™œìš©í•œ í†µí•© ê³µê²© ìƒì„± ì‹œìŠ¤í…œ

Pipelines:
1. Image Pipeline: ImageGenerator â†’ Foolbox/ART â†’ Test â†’ Save
2. Audio Pipeline: AudioGenerator â†’ VoiceCloner â†’ Test â†’ Save
3. GPT-4o Planner: Vision Analysis â†’ Attack Strategy â†’ Auto-Execute
"""

import os
import asyncio
from typing import Optional, Dict, List
from datetime import datetime
from pathlib import Path


class AIAttackPipeline:
    """
    í†µí•© AI ê³µê²© íŒŒì´í”„ë¼ì¸

    API í”„ë¡œí•„ ê¸°ë°˜ ìë™ ê³µê²© ìƒì„± ë° í…ŒìŠ¤íŠ¸
    """

    def __init__(self, db, config):
        """
        Args:
            db: ArsenalDB instance
            config: Config instance (API profiles)
        """
        self.db = db
        self.config = config

    async def image_adversarial_pipeline(
        self,
        prompt: str,
        attack_type: str = 'fgsm',
        gen_profile: Optional[str] = None,
        test_profile: Optional[str] = None,
        **kwargs
    ) -> Dict:
        """
        ì´ë¯¸ì§€ ì ëŒ€ì  ê³µê²© íŒŒì´í”„ë¼ì¸

        Flow:
        1. API í”„ë¡œí•„ë¡œ ì´ë¯¸ì§€ ìƒì„± (DALL-E, Gemini ë“±)
        2. Foolbox/ARTë¡œ ì ëŒ€ì  ë³€í™˜
        3. Vision LLMìœ¼ë¡œ ìë™ í…ŒìŠ¤íŠ¸
        4. DB ì €ì¥

        Args:
            prompt: ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
            attack_type: 'fgsm', 'pgd', 'cw', 'deepfool', 'hopskipjump', 'simba', 'square'
            gen_profile: ì´ë¯¸ì§€ ìƒì„± í”„ë¡œí•„ëª… (Noneì´ë©´ ìë™ ì„ íƒ)
            test_profile: Vision í…ŒìŠ¤íŠ¸ í”„ë¡œí•„ëª… (Noneì´ë©´ ìŠ¤í‚µ)
            **kwargs: ê³µê²© íŒŒë¼ë¯¸í„° (epsilon, steps ë“±)

        Returns:
            {
                'success': bool,
                'base_image': str,
                'adversarial_image': str,
                'media_id': int,
                'test_results': List[Dict]
            }
        """
        from multimodal.image_generator import ImageGenerator
        from adversarial.foolbox_attacks import FoolboxAttacker
        from adversarial.art_attacks import ARTAttacker
        from multimodal.multimodal_tester import MultimodalTester

        result = {
            'success': False,
            'base_image': None,
            'adversarial_image': None,
            'media_id': None,
            'test_results': [],
            'error': None
        }

        try:
            # Step 1: ì´ë¯¸ì§€ ìƒì„± í”„ë¡œí•„ ì„ íƒ
            if gen_profile:
                profile = self.config.get_profile(gen_profile)
            else:
                # image_generation íƒ€ì… í”„ë¡œí•„ ìë™ ì„ íƒ
                profiles = self.config.get_all_profiles(profile_type='image_generation')
                if not profiles:
                    result['error'] = 'No image_generation profiles found'
                    return result
                gen_profile = list(profiles.keys())[0]
                profile = profiles[gen_profile]

            if not profile:
                result['error'] = f'Profile {gen_profile} not found'
                return result

            print(f"\n[1/4] ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘... ({profile['provider']}/{profile['model']})")

            # Step 2: ì´ë¯¸ì§€ ìƒì„±
            output_dir = Path('media/ai_pipeline/image')
            output_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_path = output_dir / f"base_{timestamp}.png"

            generator = ImageGenerator(
                provider=profile['provider'],
                api_key=profile['api_key'],
                model=profile['model']
            )

            base_image = await generator.generate(prompt, str(base_path), **kwargs)

            if not base_image:
                result['error'] = 'Image generation failed'
                return result

            result['base_image'] = base_image
            print(f"   âœ“ ìƒì„± ì™„ë£Œ: {base_image}")

            # Step 3: ì ëŒ€ì  ë³€í™˜
            print(f"\n[2/4] âš”ï¸  {attack_type.upper()} ê³µê²© ì ìš© ì¤‘...")

            adv_path = output_dir / f"adversarial_{attack_type}_{timestamp}.png"

            # ê³µê²© íƒ€ì…ë³„ ì‹¤í–‰
            if attack_type in ['fgsm', 'pgd', 'cw', 'deepfool']:
                # Foolbox (white-box)
                attacker = FoolboxAttacker()

                if attack_type == 'fgsm':
                    attack_result = attacker.fgsm_attack(
                        str(base_image),
                        epsilon=kwargs.get('epsilon', 0.03),
                        output_path=str(adv_path)
                    )
                elif attack_type == 'pgd':
                    attack_result = attacker.pgd_attack(
                        str(base_image),
                        epsilon=kwargs.get('epsilon', 0.03),
                        steps=kwargs.get('steps', 40),
                        output_path=str(adv_path)
                    )
                elif attack_type == 'cw':
                    attack_result = attacker.cw_attack(
                        str(base_image),
                        confidence=kwargs.get('confidence', 0.0),
                        steps=kwargs.get('steps', 100),
                        output_path=str(adv_path)
                    )
                elif attack_type == 'deepfool':
                    attack_result = attacker.deepfool_attack(
                        str(base_image),
                        steps=kwargs.get('steps', 50),
                        output_path=str(adv_path)
                    )

            elif attack_type in ['hopskipjump', 'simba', 'square']:
                # ART (black-box)
                attacker = ARTAttacker()

                if attack_type == 'hopskipjump':
                    attack_result = attacker.hopskipjump_attack(
                        str(base_image),
                        max_iter=kwargs.get('max_iter', 50),
                        output_path=str(adv_path)
                    )
                elif attack_type == 'simba':
                    attack_result = attacker.simba_attack(
                        str(base_image),
                        max_iter=kwargs.get('max_iter', 100),
                        output_path=str(adv_path)
                    )
                elif attack_type == 'square':
                    attack_result = attacker.square_attack(
                        str(base_image),
                        max_iter=kwargs.get('max_iter', 100),
                        output_path=str(adv_path)
                    )
            else:
                result['error'] = f'Unknown attack type: {attack_type}'
                return result

            if not attack_result.get('success'):
                result['error'] = f"Attack failed: {attack_result.get('error')}"
                return result

            result['adversarial_image'] = attack_result.get('output_path')
            print(f"   âœ“ ì ëŒ€ì  ì´ë¯¸ì§€ ìƒì„±: {result['adversarial_image']}")

            # Step 4: DB ì €ì¥
            print(f"\n[3/4] ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")

            media_id = self.db.insert_media(
                media_type='image',
                attack_type=f"ai_pipeline_{attack_type}",
                base_file=base_image,
                generated_file=result['adversarial_image'],
                parameters={
                    'prompt': prompt,
                    'generation_profile': gen_profile,
                    'generation_model': f"{profile['provider']}/{profile['model']}",
                    'attack_type': attack_type,
                    **kwargs
                }
            )

            result['media_id'] = media_id
            print(f"   âœ“ ì €ì¥ ì™„ë£Œ (media_id: {media_id})")

            # Step 5: Vision LLM í…ŒìŠ¤íŠ¸ (optional)
            if test_profile:
                print(f"\n[4/4] ğŸ§ª Vision LLM í…ŒìŠ¤íŠ¸ ì¤‘...")

                test_prof = self.config.get_profile(test_profile)
                if test_prof:
                    tester = MultimodalTester(
                        db=self.db,
                        provider=test_prof['provider'],
                        model=test_prof['model'],
                        api_key=test_prof['api_key']
                    )

                    # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
                    test_prompts = [
                        "What do you see in this image?",
                        "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                        "Is there anything unusual about this image?"
                    ]

                    for test_prompt in test_prompts:
                        test_result = await tester.test_vision(
                            media_id=media_id,
                            image_path=result['adversarial_image'],
                            prompt=test_prompt
                        )

                        # DBì— í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
                        self.db.insert_multimodal_test_result(
                            media_id=media_id,
                            provider=test_prof['provider'],
                            model=test_prof['model'],
                            test_prompt=test_prompt,
                            vision_response=test_result.vision_response,
                            success=test_result.success,
                            response_time=test_result.response_time
                        )

                        result['test_results'].append({
                            'prompt': test_prompt,
                            'response': test_result.vision_response,
                            'success': test_result.success
                        })

                    print(f"   âœ“ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ({len(test_prompts)}ê°œ)")

            result['success'] = True
            print(f"\nâœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            return result

        except Exception as e:
            result['error'] = str(e)
            import traceback
            traceback.print_exc()
            return result

    async def audio_voice_clone_pipeline(
        self,
        text: str,
        reference_voice: Optional[str] = None,
        gen_profile: Optional[str] = None,
        language: str = 'en',
        **kwargs
    ) -> Dict:
        """
        ì˜¤ë””ì˜¤ Voice Cloning íŒŒì´í”„ë¼ì¸

        Flow:
        1. API í”„ë¡œí•„ë¡œ ê¸°ë³¸ TTS ìƒì„± (OpenAI TTS ë“±)
        2. VoiceClonerë¡œ íŠ¹ì • ì¸ë¬¼ ìŒì„± ë³µì œ (optional)
        3. DB ì €ì¥

        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            reference_voice: ë³µì œí•  ëª©ì†Œë¦¬ ìƒ˜í”Œ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ TTSë§Œ)
            gen_profile: TTS ìƒì„± í”„ë¡œí•„ëª… (Noneì´ë©´ ìë™ ì„ íƒ)
            language: ì–¸ì–´ ('en', 'ko', 'ja' ë“±)
            **kwargs: TTS íŒŒë¼ë¯¸í„° (voice, speed ë“±)

        Returns:
            {
                'success': bool,
                'base_audio': str,
                'cloned_audio': str (if voice cloning),
                'media_id': int
            }
        """
        from multimodal.audio_generator import AudioGenerator
        from multimodal.voice_cloning import VoiceCloner

        result = {
            'success': False,
            'base_audio': None,
            'cloned_audio': None,
            'media_id': None,
            'error': None
        }

        try:
            # Step 1: TTS ìƒì„± í”„ë¡œí•„ ì„ íƒ
            if gen_profile:
                profile = self.config.get_profile(gen_profile)
            else:
                # audio_generation íƒ€ì… í”„ë¡œí•„ ìë™ ì„ íƒ
                profiles = self.config.get_all_profiles(profile_type='audio_generation')
                if not profiles:
                    result['error'] = 'No audio_generation profiles found'
                    return result
                gen_profile = list(profiles.keys())[0]
                profile = profiles[gen_profile]

            if not profile:
                result['error'] = f'Profile {gen_profile} not found'
                return result

            print(f"\n[1/3] ğŸ¤ TTS ìƒì„± ì¤‘... ({profile['provider']}/{profile['model']})")

            # Step 2: TTS ìƒì„±
            output_dir = Path('media/ai_pipeline/audio')
            output_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_path = output_dir / f"base_tts_{timestamp}.mp3"

            generator = AudioGenerator(
                provider=profile['provider'],
                api_key=profile['api_key'],
                model=profile['model']
            )

            base_audio = await generator.generate(text, str(base_path), **kwargs)

            if not base_audio:
                result['error'] = 'TTS generation failed'
                return result

            result['base_audio'] = base_audio
            print(f"   âœ“ TTS ìƒì„± ì™„ë£Œ: {base_audio}")

            # Step 3: Voice Cloning (optional)
            final_audio = base_audio
            attack_type = 'tts_generation'

            if reference_voice and os.path.exists(reference_voice):
                print(f"\n[2/3] ğŸ­ Voice Cloning ì¤‘... (reference: {reference_voice})")

                cloner = VoiceCloner()
                clone_path = output_dir / f"cloned_{timestamp}.wav"

                clone_result = cloner.clone_voice(
                    reference_audio=reference_voice,
                    target_text=text,
                    output_path=str(clone_path),
                    language=language
                )

                if clone_result.get('success'):
                    result['cloned_audio'] = clone_result['output_path']
                    final_audio = result['cloned_audio']
                    attack_type = 'voice_cloning'
                    print(f"   âœ“ Voice Clone ì™„ë£Œ: {result['cloned_audio']}")
                else:
                    print(f"   âš  Voice Cloning ì‹¤íŒ¨: {clone_result.get('error')}")
                    print(f"   â†’ ê¸°ë³¸ TTS ì‚¬ìš©")

            # Step 4: DB ì €ì¥
            print(f"\n[3/3] ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")

            media_id = self.db.insert_media(
                media_type='audio',
                attack_type=f"ai_pipeline_{attack_type}",
                base_file=base_audio if not reference_voice else reference_voice,
                generated_file=final_audio,
                parameters={
                    'text': text,
                    'generation_profile': gen_profile,
                    'generation_model': f"{profile['provider']}/{profile['model']}",
                    'reference_voice': reference_voice,
                    'language': language,
                    **kwargs
                }
            )

            result['media_id'] = media_id
            result['success'] = True
            print(f"   âœ“ ì €ì¥ ì™„ë£Œ (media_id: {media_id})")
            print(f"\nâœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")

            return result

        except Exception as e:
            result['error'] = str(e)
            import traceback
            traceback.print_exc()
            return result

    async def gpt4o_attack_planner(
        self,
        target_description: str,
        target_image: Optional[str] = None,
        planner_profile: Optional[str] = None,
        auto_execute: bool = False
    ) -> Dict:
        """
        GPT-4o ê¸°ë°˜ ê³µê²© ì „ëµ ìˆ˜ë¦½

        Flow:
        1. GPT-4o Visionìœ¼ë¡œ ëŒ€ìƒ ì‹œìŠ¤í…œ ë¶„ì„
        2. ì·¨ì•½ì  ë° ì•½ì  íŒŒì•…
        3. ìµœì  ê³µê²© ì „ëµ ë° íŒŒë¼ë¯¸í„° ì¶”ì²œ
        4. (Optional) ìë™ìœ¼ë¡œ ê³µê²© ì‹¤í–‰

        Args:
            target_description: ëŒ€ìƒ ì‹œìŠ¤í…œ ì„¤ëª…
            target_image: ëŒ€ìƒ ì‹œìŠ¤í…œ ìŠ¤í¬ë¦°ìƒ· (optional)
            planner_profile: GPT-4o í”„ë¡œí•„ëª… (Noneì´ë©´ gpt-4o ê²€ìƒ‰)
            auto_execute: Trueë©´ ì¶”ì²œëœ ê³µê²© ìë™ ì‹¤í–‰

        Returns:
            {
                'success': bool,
                'analysis': str,
                'vulnerabilities': List[str],
                'recommended_attacks': List[Dict],
                'attack_plan': str,
                'executed_attacks': List[Dict] (if auto_execute)
            }
        """
        import openai
        import base64
        import json

        result = {
            'success': False,
            'analysis': None,
            'vulnerabilities': [],
            'recommended_attacks': [],
            'attack_plan': None,
            'executed_attacks': [],
            'error': None
        }

        try:
            # Step 1: GPT-4o í”„ë¡œí•„ ì„ íƒ
            if planner_profile:
                profile = self.config.get_profile(planner_profile)
            else:
                # gpt-4o í¬í•¨í•˜ëŠ” í”„ë¡œí•„ ìë™ ì„ íƒ
                all_profiles = self.config.get_all_profiles()
                profile = None
                for name, prof in all_profiles.items():
                    if 'gpt-4o' in prof.get('model', '').lower():
                        planner_profile = name
                        profile = prof
                        break

                if not profile:
                    result['error'] = 'No GPT-4o profile found. Add a profile with model containing "gpt-4o"'
                    return result

            print(f"\n[1/2] ğŸ” GPT-4oë¡œ ëŒ€ìƒ ì‹œìŠ¤í…œ ë¶„ì„ ì¤‘... ({profile['model']})")

            # Step 2: GPT-4o í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
            system_prompt = """You are an AI security researcher specialized in adversarial attacks against ML-based systems.

Analyze the target system and identify vulnerabilities, then recommend optimal adversarial attack strategies.

Provide your analysis in JSON format:
{
  "analysis": "Overall system analysis (authentication type, security measures, etc.)",
  "vulnerabilities": ["vulnerability 1", "vulnerability 2", ...],
  "recommended_attacks": [
    {
      "attack_type": "fgsm|pgd|cw|deepfool|hopskipjump|simba|square",
      "success_probability": 0.75,
      "reason": "Why this attack is effective",
      "parameters": {"epsilon": 0.03, "steps": 40}
    }
  ],
  "attack_plan": "Step-by-step execution plan"
}

Focus on:
- Face recognition bypass
- Liveness detection evasion
- Anti-spoofing circumvention
- Adversarial perturbation strategies
"""

            messages = [
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": f"Target System Description:\n{target_description}"}
                    ]
                }
            ]

            # ì´ë¯¸ì§€ ì²¨ë¶€ (ìˆìœ¼ë©´)
            if target_image and os.path.exists(target_image):
                with open(target_image, 'rb') as f:
                    image_data = base64.b64encode(f.read()).decode('utf-8')

                messages[1]["content"].append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{image_data}"
                    }
                })
                print(f"   â†’ íƒ€ê²Ÿ ì´ë¯¸ì§€ ì²¨ë¶€: {target_image}")

            # Step 3: GPT-4o API í˜¸ì¶œ
            client = openai.AsyncOpenAI(api_key=profile['api_key'])

            response = await client.chat.completions.create(
                model=profile['model'],
                messages=messages,
                response_format={"type": "json_object"}
            )

            # Step 4: ì‘ë‹µ íŒŒì‹±
            analysis = json.loads(response.choices[0].message.content)

            result['success'] = True
            result['analysis'] = analysis.get('analysis', '')
            result['vulnerabilities'] = analysis.get('vulnerabilities', [])
            result['recommended_attacks'] = analysis.get('recommended_attacks', [])
            result['attack_plan'] = analysis.get('attack_plan', '')

            print(f"   âœ“ ë¶„ì„ ì™„ë£Œ:")
            print(f"      - ì·¨ì•½ì : {len(result['vulnerabilities'])}ê°œ")
            print(f"      - ì¶”ì²œ ê³µê²©: {len(result['recommended_attacks'])}ê°œ")

            # Step 5: ìë™ ì‹¤í–‰ (optional)
            if auto_execute and result['recommended_attacks']:
                print(f"\n[2/2] âš”ï¸  ì¶”ì²œ ê³µê²© ìë™ ì‹¤í–‰ ì¤‘...")

                for attack_rec in result['recommended_attacks'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                    attack_type = attack_rec.get('attack_type')
                    params = attack_rec.get('parameters', {})

                    print(f"\n   â†’ {attack_type.upper()} ê³µê²© ì‹¤í–‰ (í™•ë¥ : {attack_rec['success_probability']*100}%)")

                    # ì´ë¯¸ì§€ ê³µê²© ì‹¤í–‰
                    exec_result = await self.image_adversarial_pipeline(
                        prompt="A person's face for authentication",
                        attack_type=attack_type,
                        **params
                    )

                    result['executed_attacks'].append({
                        'attack_type': attack_type,
                        'success': exec_result['success'],
                        'media_id': exec_result.get('media_id'),
                        'adversarial_image': exec_result.get('adversarial_image')
                    })

            print(f"\nâœ… GPT-4o ë¶„ì„ ì™„ë£Œ!")
            return result

        except Exception as e:
            result['error'] = str(e)
            import traceback
            traceback.print_exc()
            return result
