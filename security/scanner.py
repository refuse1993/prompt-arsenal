"""
Security Scanner - Main Orchestrator
ì •ì  ë¶„ì„ ë„êµ¬ + LLM ê²€ì¦ì„ í†µí•œ CWE ê¸°ë°˜ ì·¨ì•½ì  ìŠ¤ìº”
"""

import asyncio
import time
from typing import List, Dict, Any, Optional
from pathlib import Path

from .models import Finding, SecurityReport, ScanConfig
from .static.tool_runner import ToolRunner


class SecurityScanner:
    """
    ë³´ì•ˆ ìŠ¤ìºë„ˆ ë©”ì¸ í´ë˜ìŠ¤

    ì§€ì› ëª¨ë“œ:
    - rule_only: ì •ì  ë¶„ì„ ë„êµ¬ë§Œ ì‚¬ìš©
    - verify_with_llm: ë„êµ¬ ê²°ê³¼ â†’ LLM ê²€ì¦
    - llm_detect: LLM íƒì§€ â†’ ë„êµ¬ êµì°¨ ê²€ì¦
    - hybrid: ì‹ ë¢°ë„ ê¸°ë°˜ ì„ íƒì  LLM ê²€ì¦
    """

    def __init__(self, config: ScanConfig, db=None):
        """
        Args:
            config: ìŠ¤ìº” ì„¤ì •
            db: ArsenalDB ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ)
        """
        self.config = config
        self.db = db
        self.tool_runner = ToolRunner()

        # LLM ë¶„ì„ê¸°ëŠ” í•„ìš” ì‹œì—ë§Œ ì´ˆê¸°í™”
        self.llm_analyzer = None
        if config.enable_llm_verification and config.profile_name:
            self._init_llm_analyzer()

    def _init_llm_analyzer(self):
        """LLM ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        try:
            from .llm.analyzer import LLMSecurityAnalyzer
            self.llm_analyzer = LLMSecurityAnalyzer(self.config.profile_name, self.db)
            print(f"âœ… LLM analyzer initialized: {self.llm_analyzer.provider}/{self.llm_analyzer.model}")
        except Exception as e:
            print(f"âš ï¸  LLM analyzer initialization failed: {e}")
            self.llm_analyzer = None

    async def scan(self) -> SecurityReport:
        """
        ë©”ì¸ ìŠ¤ìº” í•¨ìˆ˜

        Returns:
            SecurityReport with findings and statistics
        """
        start_time = time.time()
        report = SecurityReport(
            target=self.config.target,
            mode=self.config.mode,
            scan_type="static"
        )

        # ëª¨ë“œë³„ ìŠ¤ìº” ì‹¤í–‰
        if self.config.mode == "rule_only":
            findings = await self._scan_rule_only()
        elif self.config.mode == "verify_with_llm":
            findings = await self._scan_verify_with_llm()
        elif self.config.mode == "llm_detect":
            findings = await self._scan_llm_detect()
        elif self.config.mode == "hybrid":
            findings = await self._scan_hybrid()
        else:
            raise ValueError(f"Unknown mode: {self.config.mode}")

        # ê²°ê³¼ ì €ì¥
        report.findings = findings
        report.scan_duration = time.time() - start_time

        # LLM í†µê³„ ì¶”ê°€
        if self.llm_analyzer:
            stats = self.llm_analyzer.get_stats()
            report.llm_calls = stats['calls']
            report.llm_cost = stats['total_cost']

        report.calculate_stats()

        return report

    async def _scan_rule_only(self) -> List[Finding]:
        """
        Mode 1: ì •ì  ë¶„ì„ ë„êµ¬ë§Œ ì‚¬ìš©
        ê°€ì¥ ë¹ ë¥´ì§€ë§Œ False Positive ê°€ëŠ¥ì„± ìˆìŒ
        """
        # ëª¨ë“  ë„êµ¬ ë³‘ë ¬ ì‹¤í–‰
        tool_results = await self.tool_runner.run_all_tools(self.config.target)

        # ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
        all_findings = []
        for tool_name, findings in tool_results.items():
            all_findings.extend(findings)

        # ì¤‘ë³µ ì œê±° (ê°™ì€ íŒŒì¼, ê°™ì€ ë¼ì¸, ê°™ì€ CWE)
        unique_findings = self._deduplicate_findings(all_findings)

        return unique_findings

    async def _scan_verify_with_llm(self) -> List[Finding]:
        """
        Mode 2: ë„êµ¬ ê²°ê³¼ â†’ LLM ê²€ì¦
        ëª¨ë“  ë°œê²¬ì‚¬í•­ì„ LLMìœ¼ë¡œ ê²€ì¦ (False Positive í•„í„°ë§)
        """
        # 1. ë„êµ¬ ì‹¤í–‰
        initial_findings = await self._scan_rule_only()

        if not self.llm_analyzer:
            print("âš ï¸  LLM analyzer not available, falling back to rule_only mode")
            return initial_findings

        print(f"ğŸ¤– Verifying {len(initial_findings)} findings with LLM...")

        # 2. LLM ê²€ì¦
        verified_findings = []
        false_positives = 0

        for i, finding in enumerate(initial_findings, 1):
            print(f"  [{i}/{len(initial_findings)}] Verifying {finding.cwe_id} in {finding.file_path}:{finding.line_number}")

            is_valid, reasoning = await self.llm_analyzer.verify_finding(finding)

            if is_valid:
                finding.verified_by = f"{finding.verified_by}+llm"
                finding.llm_reasoning = reasoning
                verified_findings.append(finding)
            else:
                finding.is_false_positive = True
                false_positives += 1
                print(f"    âœ— False positive: {reasoning[:80]}...")

        print(f"âœ… Verification complete: {len(verified_findings)} valid, {false_positives} false positives")

        return verified_findings

    async def _scan_llm_detect(self) -> List[Finding]:
        """
        Mode 3: LLM íƒì§€ â†’ ë„êµ¬ êµì°¨ ê²€ì¦
        LLMì´ ë¨¼ì € ì·¨ì•½ì ì„ ì°¾ê³ , ë„êµ¬ë¡œ í™•ì¸
        """
        if not self.llm_analyzer:
            print("âš ï¸  LLM analyzer required for llm_detect mode")
            return []

        # 1. Get code files to scan
        from pathlib import Path
        target_path = Path(self.config.target)

        if target_path.is_file():
            files_to_scan = [str(target_path)]
        else:
            # Get all supported code files in directory
            supported_extensions = [
                '.py', '.js', '.ts', '.jsx', '.tsx', '.vue', '.svelte',
                '.java', '.kt', '.scala',
                '.go', '.rs',
                '.c', '.cpp', '.cc', '.h', '.hpp',
                '.php', '.rb', '.sh', '.bash',
                '.cs', '.swift', '.m', '.mm',
                '.html', '.xml', '.sql'
            ]
            files_to_scan = [
                str(f) for f in target_path.rglob("*")
                if f.suffix.lower() in supported_extensions
            ]

        print(f"ğŸ¤– LLM detecting vulnerabilities in {len(files_to_scan)} files...")

        # 2. LLM detection for each file
        llm_findings = []
        for i, file_path in enumerate(files_to_scan, 1):
            print(f"  [{i}/{len(files_to_scan)}] Analyzing {file_path}")
            findings = await self.llm_analyzer.detect_vulnerabilities(file_path)
            llm_findings.extend(findings)
            print(f"    Found {len(findings)} potential issues")

        print(f"ğŸ“Š LLM found {len(llm_findings)} total findings")

        # 3. Cross-verify with tool results
        print("ğŸ”§ Cross-verifying with static analysis tools...")
        tool_findings = await self._scan_rule_only()

        # 4. Cross-verify
        cross_verified = self._cross_verify(llm_findings, tool_findings)

        print(f"âœ… Cross-verification complete: {len(cross_verified)} findings")

        return cross_verified

    async def _scan_hybrid(self) -> List[Finding]:
        """
        Mode 4: Hybrid - ì‹ ë¢°ë„ ê¸°ë°˜ ì„ íƒì  LLM ê²€ì¦

        ì „ëµ:
        - ë„êµ¬ confidence >= threshold â†’ ìë™ í™•ì •
        - ë„êµ¬ confidence < threshold â†’ LLM ê²€ì¦

        ëª©í‘œ: 80% ë¹„ìš© ì ˆê° + 95% ì •í™•ë„ ìœ ì§€
        """
        # 1. ë„êµ¬ ì‹¤í–‰
        all_findings = await self._scan_rule_only()

        if not self.llm_analyzer:
            print("âš ï¸  LLM analyzer not available, using rule_only results")
            return all_findings

        # 2. ì‹ ë¢°ë„ ê¸°ë°˜ ë¶„ë¥˜
        high_confidence = []
        low_confidence = []

        threshold = self.config.llm_confidence_threshold
        for finding in all_findings:
            if finding.confidence >= threshold:
                high_confidence.append(finding)
            else:
                low_confidence.append(finding)

        print(f"\nğŸ“Š ì‹ ë¢°ë„ ê¸°ë°˜ ë¶„ë¥˜ ì™„ë£Œ:")
        print(f"  âœ… High confidence: {len(high_confidence)}ê°œ (ìë™ í™•ì •)")
        if high_confidence:
            for finding in high_confidence:
                print(f"    â€¢ {finding.severity}: {finding.cwe_id} - {finding.file_path}:{finding.line_number}")
        print(f"  ğŸ” Low confidence: {len(low_confidence)}ê°œ (LLM ê²€ì¦ í•„ìš”)")

        # 3. Low confidenceë§Œ LLM ê²€ì¦ (80% ë¹„ìš© ì ˆê° ëª©í‘œ)
        verified_findings = high_confidence.copy()
        false_positives = 0

        if low_confidence:
            print(f"ğŸ¤– Verifying {len(low_confidence)} low-confidence findings with LLM...")

            for i, finding in enumerate(low_confidence, 1):
                print(f"  [{i}/{len(low_confidence)}] Verifying {finding.cwe_id} in {finding.file_path}:{finding.line_number}")

                is_valid, reasoning = await self.llm_analyzer.verify_finding(finding)

                if is_valid:
                    finding.verified_by = f"{finding.verified_by}+llm"
                    finding.llm_reasoning = reasoning
                    finding.confidence = 0.9  # LLM ê²€ì¦ í›„ ì‹ ë¢°ë„ ìƒìŠ¹
                    verified_findings.append(finding)
                    print(f"    âœ“ Valid - {finding.severity}: {finding.cwe_id} ({finding.file_path}:{finding.line_number})")
                else:
                    finding.is_false_positive = True
                    false_positives += 1
                    print(f"    âœ— False positive: {reasoning[:80]}...")

            print(f"âœ… Hybrid scan complete: {len(high_confidence)} auto-confirmed, {len(low_confidence) - false_positives} LLM-verified, {false_positives} false positives")

        return verified_findings

    def _deduplicate_findings(self, findings: List[Finding]) -> List[Finding]:
        """
        ì¤‘ë³µ ì œê±° ë¡œì§

        ê°™ì€ íŒŒì¼, ê°™ì€ ë¼ì¸, ê°™ì€ CWE â†’ ê°€ì¥ ë†’ì€ confidenceë§Œ ìœ ì§€
        """
        unique = {}

        for finding in findings:
            # í‚¤: (íŒŒì¼ê²½ë¡œ, ë¼ì¸ë²ˆí˜¸, CWE ID)
            key = (finding.file_path, finding.line_number, finding.cwe_id)

            if key not in unique:
                unique[key] = finding
            else:
                # ë” ë†’ì€ confidenceë¥¼ ê°€ì§„ ê²ƒìœ¼ë¡œ ëŒ€ì²´
                if finding.confidence > unique[key].confidence:
                    unique[key] = finding

        return list(unique.values())

    def _cross_verify(
        self,
        llm_findings: List[Finding],
        tool_findings: List[Finding]
    ) -> List[Finding]:
        """
        LLM ê²°ê³¼ì™€ ë„êµ¬ ê²°ê³¼ êµì°¨ ê²€ì¦

        ì–‘ìª½ì—ì„œ ëª¨ë‘ ë°œê²¬ëœ ê²ƒ â†’ ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„
        í•œìª½ë§Œ ë°œê²¬ â†’ ë‚®ì€ ì‹ ë¢°ë„ (ì¶”ê°€ ê²€í†  í•„ìš”)
        """
        # ë„êµ¬ ë°œê²¬ì‚¬í•­ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        tool_dict = {}
        for finding in tool_findings:
            key = (finding.file_path, finding.line_number, finding.cwe_id)
            tool_dict[key] = finding

        # êµì°¨ ê²€ì¦
        verified = []
        for llm_finding in llm_findings:
            key = (llm_finding.file_path, llm_finding.line_number, llm_finding.cwe_id)

            if key in tool_dict:
                # ì–‘ìª½ì—ì„œ ë°œê²¬ â†’ ë†’ì€ ì‹ ë¢°ë„
                tool_finding = tool_dict[key]
                llm_finding.confidence = 0.95
                llm_finding.verified_by = f"llm+{tool_finding.verified_by}"
                verified.append(llm_finding)
            else:
                # LLMë§Œ ë°œê²¬ â†’ ë‚®ì€ ì‹ ë¢°ë„
                llm_finding.confidence = 0.6
                verified.append(llm_finding)

        return verified

    async def save_to_db(self, report: SecurityReport) -> int:
        """
        ìŠ¤ìº” ê²°ê³¼ë¥¼ DBì— ì €ì¥

        Returns:
            scan_id
        """
        if not self.db:
            raise ValueError("Database not available")

        # Insert scan report
        scan_id = self.db.insert_security_scan(report)

        # Insert all findings
        for finding in report.findings:
            self.db.insert_security_finding(scan_id, finding)

        return scan_id
